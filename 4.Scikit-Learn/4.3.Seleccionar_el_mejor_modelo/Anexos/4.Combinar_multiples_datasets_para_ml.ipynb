{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinar mÃºltiples datasets para ML \n",
    "\n",
    "Para muchos casos de uso, la combinaciÃ³n de informaciÃ³n de diferentes datasets puede ser interesante para mejorar el rendimiento de un modelo, especialmente cuando el nÃºmero de muestras de al menos uno de los conjuntos de datos es pequeÃ±o.\n",
    "\n",
    "Un desafÃ­o adicional en tales casos es que las caracterÃ­sticas de estos conjuntos de datos no son idÃ©nticas, a pesar de que hay algunas caracterÃ­sticas comÃºnmente compartidas entre los conjuntos de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4624723",
   "metadata": {},
   "source": [
    "## **Proceso de combinaciÃ³n**\n",
    "\n",
    "### **1. Limpieza de datos**\n",
    "Antes de pensar en combinar datasets, es **crucial limpiarlos** individualmente. \n",
    "- La limpieza de datos implica eliminar o corregir imprecisiones, manejar valores faltantes y estandarizar los formatos de datos. \n",
    "- Por ejemplo, se puede usar `fillna()` de Pandas para abordar los valores nulos. \n",
    "- Asegurar que cada conjunto de datos estÃ© limpio y consistente es la base para una integraciÃ³n exitosa. \n",
    "- Es como preparar ingredientes antes de combinarlos en una comida: cada uno debe estar fresco y listo para contribuir al sabor general.\n",
    "\n",
    "\n",
    "### **2. Matching de esquemas**\n",
    "Cuando los datasets provienen de diferentes fuentes, a menudo tienen esquemas o estructuras dispares. \n",
    "- El matching de esquemas es el proceso de encontrar correspondencias entre elementos de datos que representan el mismo concepto en todos los datasets. \n",
    "- Es posible que se deba cambiar el nombre de columnas o reformatear los tipos de datos para alinearlas. \n",
    "- Por ejemplo, si un conjunto de datos tiene una columna llamada \"Fecha de nacimiento\" y otra tiene \"DOB\" (Date of Birth), se cambiarÃ¡ el nombre de estas columnas para que coincidan antes de fusionar.\n",
    "\n",
    "\n",
    "### **3. Feature Engineering**\n",
    "La ingenierÃ­a de caracterÃ­sticas es el arte de transformar datos sin procesar en caracterÃ­sticas que representan mejor el problema subyacente a los modelos predictivos. \n",
    "- Al combinar datasets, es posible que se deban crear nuevas caracterÃ­sticas o modificar las existentes para que sean compatibles en los datasets. \n",
    "- Por ejemplo, si un conjunto de datos tiene la temperatura en Celsius y otro en Fahrenheit, se podrÃ­a crear una nueva caracterÃ­stica en una escala unificada o convertir las mediciones para que coincida la una con la otra.\n",
    "\n",
    "\n",
    "### **4. FusiÃ³n de datos**\n",
    "La fusiÃ³n de datos es el proceso real de integrar mÃºltiples datasets en un conjunto de datos Ãºnico, consistente y comprehensivo. \n",
    "- AquÃ­ se utilizan tÃ©cnicas como la concatenaciÃ³n, donde se apilan los datasets verticalmente u horizontalmente, o mÃ©todos mÃ¡s complejos como joins. \n",
    "- Por ejemplo, puede usar `pd.concat()` para un apilamiento sencillo, o `p.merge()` para mezclar datasets basados â€‹â€‹en claves comunes.\n",
    "\n",
    "### **5. GestiÃ³n de duplicados**\n",
    "DespuÃ©s de fusionar datasets, se pueden encontrar entradas duplicadas. \n",
    "- Los duplicados pueden sesgar el anÃ¡lisis y conducir a conclusiones erroneas. \n",
    "- Es esencial identificar y eliminar estos duplicados para mantener la integridad de sus datos. \n",
    "- Esto se puede hacer utilizando funciones como `drop_dupplicates()`, que permite especificar el subconjunto de columnas a considerar para identificar duplicados.\n",
    "\n",
    "### **6. VerificaciÃ³n de consistencia**\n",
    "Una vez que se combinan los datasets, se deben realizar verificaciones de consistencia para garantizar que los datos tengan sentido. \n",
    "- Buscar anomalÃ­as que puedan indicar problemas con la fusiÃ³n, como tipos de datos no coincidentes o valores ilÃ³gicos que no se alineen con el resto de su conjunto de datos. \n",
    "- Este paso es similar a la revisiÃ³n de un documento despuÃ©s de fusionar contenidos de diferentes fuentes. Se trata de identificar y corregir errores para garantizar una narraciÃ³n perfecta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f32cdd",
   "metadata": {},
   "source": [
    "## **FusiÃ³n de datos**\n",
    "Combinar dos datasets con caracterÃ­sticas distintas, pero con 2 caracterÃ­sticas en comÃºn, requiere elegir una estrategia que preserve la informaciÃ³n relevante y evite problemas como la pÃ©rdida de datos o la creaciÃ³n de redundancias innecesarias. AquÃ­ tienes algunas estrategias a considerar para preparar los datos antes de entrenar un modelo en **Scikit-Learn**:\n",
    "\n",
    "\n",
    "### **1. UniÃ³n basada en las caracterÃ­sticas comunes (Join/Merge)**\n",
    "#### **1.1. UniÃ³n por clave comÃºn (Join)**\n",
    "Si las dos caracterÃ­sticas comunes pueden actuar como **claves Ãºnicas**, podemos unir los datasets de varias maneras:\n",
    "- **Inner Join**: Mantiene solo las filas que tienen coincidencia en ambas tablas.  \n",
    "- **Outer Join**: Mantiene todas las filas de ambos datasets y completa con valores `NaN` cuando falta informaciÃ³n.  \n",
    "- **Left/Right Join**: Mantiene todas las filas de un dataset y solo las coincidentes del otro.  \n",
    "\n",
    "**Ejemplo**:\n",
    "```python\n",
    "df_merged = df1.merge(df2, on=['feature1', 'feature2'], how='inner')  # 'outer', 'left', 'right'\n",
    "```\n",
    "\n",
    "**CuÃ¡ndo usarlo**:  \n",
    "- Si los datasets tienen informaciÃ³n complementaria sobre las mismas observaciones.  \n",
    "- Si las caracterÃ­sticas comunes identifican la misma entidad en ambos datasets.  \n",
    "\n",
    "\n",
    "### **2. ConcatenaciÃ³n de datasets (Stacking)**\n",
    "Si los datasets representan observaciones similares pero con distintas caracterÃ­sticas, se pueden **concatenar verticalmente** (aumentando el nÃºmero de filas) o **horizontalmente** (aumentando el nÃºmero de columnas).\n",
    "\n",
    "#### **2.1. ConcatenaciÃ³n horizontal (Column-wise)**\n",
    "Si los datos comparten el mismo orden y cada fila representa la misma entidad en ambos datasets:\n",
    "```python\n",
    "df_combined = pd.concat([df1, df2.drop(columns=['feature1', 'feature2'])], axis=1)\n",
    "```\n",
    "\n",
    "**CuÃ¡ndo usarlo**:  \n",
    "- Si cada fila en ambos datasets representa la misma entidad y estÃ¡n alineadas en el mismo orden.  \n",
    "\n",
    "#### **2.2. ConcatenaciÃ³n vertical (Row-wise)**\n",
    "Si los datasets contienen **observaciones similares pero con diferentes muestras**:\n",
    "```python\n",
    "df_combined = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "```\n",
    "**CuÃ¡ndo usarlo**:  \n",
    "- Si los datasets contienen las mismas variables pero diferentes ejemplos.  \n",
    "\n",
    "\n",
    "### **3. CreaciÃ³n de nuevas caracterÃ­sticas a partir de los datasets**\n",
    "Si ambos datasets contienen informaciÃ³n complementaria, podemos usar tÃ©cnicas como:\n",
    "- **Feature Engineering**: Crear nuevas caracterÃ­sticas a partir de la informaciÃ³n de ambos datasets.  \n",
    "- **Agregaciones y EstadÃ­sticas**: Si un dataset contiene datos agrupados (ej. transacciones de usuarios), podemos agregar la informaciÃ³n y unirla al otro dataset.  \n",
    "```python\n",
    "df_grouped = df2.groupby(['feature1', 'feature2']).agg({'some_feature': 'mean'}).reset_index()\n",
    "df_combined = df1.merge(df_grouped, on=['feature1', 'feature2'], how='left')\n",
    "```\n",
    "\n",
    "**CuÃ¡ndo usarlo**:  \n",
    "- Si un dataset tiene informaciÃ³n granular y el otro informaciÃ³n agregada.  \n",
    "\n",
    "\n",
    "### **4. ImputaciÃ³n y tratamiento de valores faltantes**\n",
    "DespuÃ©s de combinar datasets, es posible que haya valores faltantes (`NaN`). Algunas estrategias para tratarlos incluyen:\n",
    "- **Eliminar filas con valores faltantes**: `df.dropna()`\n",
    "- **Rellenar con la media/mediana/moda**: `df.fillna(df.mean())`\n",
    "- **Usar un imputador de `scikit-learn`**:\n",
    "```python\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')  # O 'median', 'most_frequent'\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "```\n",
    "\n",
    "**CuÃ¡ndo usarlo**:  \n",
    "- Si el join o la concatenaciÃ³n dejan valores nulos y no queremos perder informaciÃ³n.  \n",
    "\n",
    "\n",
    "### **5. ReducciÃ³n de Dimensionalidad**\n",
    "Si al combinar los datasets obtenemos muchas caracterÃ­sticas irrelevantes, podemos reducirlas mediante:\n",
    "- **PCA (AnÃ¡lisis de Componentes Principales)**  \n",
    "- **SelecciÃ³n de caracterÃ­sticas basada en correlaciÃ³n o importancia**  \n",
    "\n",
    "**Ejemplo usando `PCA`:**\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=10)  # Reducir a 10 dimensiones\n",
    "X_reduced = pca.fit_transform(df_combined)\n",
    "```\n",
    "\n",
    "**CuÃ¡ndo usarlo**:  \n",
    "- Si la combinaciÃ³n genera muchas caracterÃ­sticas redundantes o altamente correlacionadas.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f483528f",
   "metadata": {},
   "source": [
    "### **Conclusiones**\n",
    "- **Si los datasets representan las mismas entidades y tienen informaciÃ³n complementaria** â†’ Usa **Merge/Join**  \n",
    "- **Si los datasets tienen estructuras similares pero distintas muestras** â†’ Usa **ConcatenaciÃ³n vertical**  \n",
    "- **Si un dataset tiene datos agregados** â†’ Usa **AgregaciÃ³n y Feature Engineering**  \n",
    "- **Si la combinaciÃ³n genera muchas caracterÃ­sticas irrelevantes** â†’ Usa **ReducciÃ³n de dimensionalidad**  \n",
    "\n",
    "> **Tip:** Probar distintas estrategias y evaluar el rendimiento con validaciÃ³n cruzada puede ayudar a encontrar la mejor forma de combinar los datasets. ðŸš€"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
